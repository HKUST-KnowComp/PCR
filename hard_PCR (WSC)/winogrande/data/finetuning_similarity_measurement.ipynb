{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pickle  \n",
    "import spacy\n",
    "import json\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# from pandas import Series\n",
    "import logging\n",
    "import numpy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import os\n",
    "\n",
    "import csv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eighty', 'seven', 'miles', 'to', 'go', 'yet', 'Onward']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenizer.tokenize('Eighty-seven miles to go, yet.  Onward!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    # read a winogrande style jsonl file\n",
    "    # qID, sentence, option1, option2, answer\n",
    "    this_set = []\n",
    "    \n",
    "    \n",
    "    with open(filename,\"r\") as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "        for json_str in json_list:\n",
    "            result = json.loads(json_str)\n",
    "            this_set.append(result)\n",
    "    print(\"Loaded \"+ filename + \" with \"+ str(len(this_set)) + \" items.\")\n",
    "    return this_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded wsc.jsonl with 279 items.\n",
      "Loaded train_xs.jsonl with 160 items.\n",
      "Loaded train_s.jsonl with 640 items.\n",
      "Loaded train_m.jsonl with 2558 items.\n",
      "Loaded train_l.jsonl with 10234 items.\n",
      "Loaded train_xl.jsonl with 40398 items.\n",
      "{'qID': 'wsc0', 'sentence': 'The city councilmen refused the demonstrators a permit because _ feared violence.', 'option1': 'The city councilmen', 'option2': 'The demonstrators', 'answer': '1'}\n"
     ]
    }
   ],
   "source": [
    "wsc = load_dataset(\"wsc.jsonl\")\n",
    "xs = load_dataset(\"train_xs.jsonl\")\n",
    "s = load_dataset(\"train_s.jsonl\")\n",
    "m = load_dataset(\"train_m.jsonl\")\n",
    "l = load_dataset(\"train_l.jsonl\")\n",
    "xl = load_dataset(\"train_xl.jsonl\")\n",
    "\n",
    "# s_l = load_dataset(\"selected_l.jsonl\")\n",
    "\n",
    "# s1 = load_dataset(\"split_xl_1.jsonl\")\n",
    "# s2 = load_dataset(\"split_xl_2.jsonl\")\n",
    "# s3 = load_dataset(\"split_xl_3.jsonl\")\n",
    "print(wsc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'qID': 'wsc1', 'sentence': 'The city councilmen refused the demonstrators a permit because _ advocated violence.', 'option1': 'The city councilmen', 'option2': 'The demonstrators', 'answer': '2'}\n"
     ]
    }
   ],
   "source": [
    "print(wsc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_grande_to_bert_commonsense(dataset, name):\n",
    "    with open(name+\".txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for i,piece in enumerate(dataset):\n",
    "            text = piece[\"sentence\"].replace(\"_\", \"[MASK]\")\n",
    "            pron = \"[MASK]\"\n",
    "            op1 = piece[\"option1\"]\n",
    "            op2 = piece[\"option2\"]\n",
    "            if piece[\"answer\"] == \"1\":\n",
    "                answer = op1\n",
    "            elif piece[\"answer\"] == \"2\":\n",
    "                answer = op2\n",
    "            else:\n",
    "                print(piece)\n",
    "                print(\"ALERT!\")\n",
    "                \n",
    "            f.write(text)\n",
    "            f.write(\"\\n\")\n",
    "            f.write(pron)\n",
    "            f.write(\"\\n\")\n",
    "            f.write(op1)\n",
    "            f.write(\",\")\n",
    "            f.write(op2)\n",
    "            f.write(\"\\n\")\n",
    "            f.write(answer)\n",
    "            \n",
    "            if i != (len(dataset)-1):\n",
    "                f.write(\"\\n\")\n",
    "                f.write(\"\\n\")\n",
    "                \n",
    "def convert_commonsense_to_grande(input_name, output_name):\n",
    "    collected_info = []\n",
    "    with open(input_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        all_data = f.readlines()\n",
    "        count = 0\n",
    "        for i, data in enumerate(all_data):\n",
    "            if i%5 == 0:\n",
    "                text = data.rstrip()\n",
    "            if i%5 == 1:\n",
    "                pron = data.rstrip()\n",
    "            if i%5 == 2:\n",
    "                cands = data.split(\",\")\n",
    "            if i%5 == 3:\n",
    "                ans = data.rstrip()\n",
    "            if i%5 == 4:\n",
    "                collected_info.append([count,text,pron,cands,ans])\n",
    "    \n",
    "    print(collected_info[0])\n",
    "                \n",
    "    with open(output_name, \"w\", encoding=\"utf-8\") as f:      \n",
    "        for piece in collected_info:\n",
    "            # {'qID': 'wsc1', 'sentence': 'The city councilmen refused the demonstrators a permit because _ advocated violence.', \n",
    "            # 'option1': 'The city councilmen', 'option2': 'The demonstrators', 'answer': '2'}\n",
    "            tmp_dic = dict()\n",
    "            tmp_dic[\"qID\"] = piece[0]\n",
    "            tmp_dic[\"sentence\"] = piece[1].replace(piece[2], \"_\")\n",
    "            tmp_dic[\"option1\"] = piece[3][0]\n",
    "            tmp_dic[\"option2\"] = piece[3][1].rstrip()\n",
    "\n",
    "            if piece[-1] == tmp_dic[\"option1\"]:\n",
    "                tmp_dic[\"answer\"] = \"1\"\n",
    "            else:\n",
    "                tmp_dic[\"answer\"] = \"2\"\n",
    "            \n",
    "            f.write(json.dumps(tmp_dic))\n",
    "            f.write(\"\\n\")\n",
    "    print(tmp_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 'The bee landed on the flower because it had pollen.', 'it', ['The bee', 'the flower\\n'], 'the flower']\n",
      "{'qID': 0, 'sentence': 'There is currently more work on coreference resolution than on chunking because _ is a problem that is still far from being solved.', 'option1': 'coreference resolution', 'option2': 'chunking', 'answer': '1'}\n"
     ]
    }
   ],
   "source": [
    "# convert_grande_to_bert_commonsense(xl, \"bert_xl\")\n",
    "convert_commonsense_to_grande(\"train.c_old.txt\", \"test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison(cover_set, target_set, rule):\n",
    "    # prepare target base\n",
    "    tar_sents_collection = []\n",
    "    tar_words_collection = []\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    \n",
    "    print(\"Preparing target dataset...\")\n",
    "    \n",
    "    for query in target_set:\n",
    "        # construct the right sent\n",
    "        sentence = query[\"sentence\"].replace(\"_\", query[\"option\"+query[\"answer\"]])\n",
    "        doc = nlp(sentence)\n",
    "        useful_tokens = [token.lemma_ for token in doc if token.pos_ in [\"VERB\",\"NOUN\",\"ADP\",\"ADJ\",\"ADV\"]]\n",
    "        cleaned_sent = \" \".join(useful_tokens)\n",
    "        tar_sents_collection.append(cleaned_sent)\n",
    "        tar_words_collection.extend(cleaned_sent)\n",
    "        \n",
    "    tar = vectorizer.fit(tar_sents_collection)\n",
    "    \n",
    "    print(\"Preparing finetune dataset...\")\n",
    "    cov_sents_collection = []\n",
    "    cov_words_collection = []\n",
    "    \n",
    "    for case in tqdm(cover_set):\n",
    "        # construct the right sent\n",
    "        sentence = case[\"sentence\"].replace(\"_\", case[\"option\"+case[\"answer\"]])\n",
    "        doc = nlp(sentence)\n",
    "        useful_tokens = [token.lemma_ for token in doc if token.pos_ in [\"VERB\",\"NOUN\",\"ADP\",\"ADJ\",\"ADV\"]]\n",
    "        cleaned_sent = \" \".join(useful_tokens)\n",
    "        cov_sents_collection.append(cleaned_sent)\n",
    "        cov_words_collection.extend(cleaned_sent)\n",
    "        \n",
    "    cov_matrix = vectorizer.transform(cov_sents_collection)\n",
    "    score = sum(sum(cov_matrix.toarray()))/len(vectorizer.get_feature_names())\n",
    "    occ_score = np.count_nonzero(sum(cov_matrix.toarray()))/len(vectorizer.get_feature_names())\n",
    "    \n",
    "    print(\"The coverage score is \" + str(score))\n",
    "    print(\"The occurence score is \" + str(occ_score))\n",
    "    \n",
    "    return cov_matrix, score\n",
    "\n",
    "\n",
    "def sent_by_sent_comparison(cover_set, target_set):\n",
    "    \n",
    "    tar_words_collection = []\n",
    "    \n",
    "    print(\"Preparing target dataset...\")\n",
    "    \n",
    "    for query in target_set:\n",
    "        # construct the right sent\n",
    "        sentence = query[\"sentence\"].replace(\"_\", query[\"option\"+query[\"answer\"]])\n",
    "        doc = nlp(sentence)\n",
    "        useful_tokens = [token.lemma_ for token in doc if token.pos_ in [\"VERB\",\"NOUN\",\"ADP\",\"ADJ\",\"ADV\"]]\n",
    "        # print(useful_tokens)\n",
    "        # useful_tokens = [token.lemma_ for token in doc]\n",
    "        # useful_tokens = tokenizer.tokenize(sentence)\n",
    "        \n",
    "        tar_words_collection.append(useful_tokens)\n",
    "        \n",
    "    print(\"Preparing finetune dataset...\")\n",
    "    cov_score_mat = []\n",
    "    cov_words_collection = []\n",
    "    \n",
    "    \n",
    "    for case in tqdm(cover_set):\n",
    "        # construct the right sent\n",
    "        case_score_list = [] # 1 * len(target set)\n",
    "        sentence = case[\"sentence\"].replace(\"_\", case[\"option\"+case[\"answer\"]])\n",
    "        doc = nlp(sentence)\n",
    "        # useful_tokens = [token.lemma_ for token in doc if token.pos_ in [\"VERB\",\"NOUN\",\"ADP\",\"ADJ\",\"ADV\"]]\n",
    "        useful_tokens = [token.lemma_ for token in doc if token.pos_ in [\"VERB\",\"NOUN\",\"ADP\",\"ADJ\",\"ADV\"]]\n",
    "\n",
    "        # useful_tokens = [token.lemma_ for token in doc]\n",
    "        # cov_words_collection.extend(useful_tokens)\n",
    "        # useful_tokens = tokenizer.tokenize(sentence)\n",
    "        \n",
    "        for target in tar_words_collection:\n",
    "            score = 0\n",
    "            for token in target:\n",
    "                    if token in useful_tokens:\n",
    "                        if token not in sw:\n",
    "                            score += 1\n",
    "                        \n",
    "            new_score = (score * score)/(len(target)*len(useful_tokens))   \n",
    "            # jaccard_score = score/(len(target)+len(useful_tokens)-score)\n",
    "            \n",
    "            case_score_list.append(new_score)\n",
    "            # case_score_list.append(jaccard_score)\n",
    "            \n",
    "        cov_score_mat.append(case_score_list)\n",
    "        \n",
    "    return cov_score_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing target dataset...\n",
      "Preparing finetune dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a422ee07d4487a9f08162b120ac27e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40398), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# cov_matrix, score = comparison(xs, wsc, \"default\")\n",
    "# cov_matrix, score = comparison(s, wsc, \"default\")\n",
    "# cov_matrix, score = comparison(m, wsc, \"default\")\n",
    "# cov_matrix, score = comparison(l, wsc, \"default\")\n",
    "# cov_matrix, score = comparison(xl, wsc, \"default\")\n",
    "#cov_matrix, score = comparison(wsc, wsc, \"default\")\n",
    "\n",
    "# for sent by sent, current we have uncleaned unigram, should we use max?\n",
    "cov_score_mat = sent_by_sent_comparison(xl, wsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for i in range(len(cov_score_mat)):\n",
    "#     print(max(cov_score_mat[i]))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "score_list = []\n",
    "for tmp in cov_score_mat:\n",
    "    score_list.append(max(tmp))\n",
    "\n",
    "x = np.arange(0,len(cov_score_mat), 1);\n",
    "y = np.sort(np.array(score_list))[::-1]\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.count_nonzero(sum(cov_matrix.toarray())))\n",
    "# un_m = load_dataset(\"unselected_m.jsonl\")\n",
    "\n",
    "# _, _ = comparison(s1, wsc, \"default\")\n",
    "# _, _ = comparison(s2, wsc, \"default\")\n",
    "# _, _ = comparison(s3, wsc, \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data_pieces_ids(cov_matrix, select_num, score_bar):\n",
    "    # use the coverage matrix to extract a distilled set of winowhy\n",
    "    score_mat = cov_matrix.toarray()\n",
    "    selected_ids = []\n",
    "    selected_mat = []\n",
    "    \n",
    "    count_list = []\n",
    "    \n",
    "    for tmp in score_mat:\n",
    "        count_list.append(sum(tmp))\n",
    "    \n",
    "    # print(count_list)\n",
    "    sorted_counts = np.array(count_list).argsort()[::-1]\n",
    "    \n",
    "    num_ids = []\n",
    "    bar_ids = []\n",
    "    \n",
    "    # selection by number\n",
    "    for i in tqdm(range(select_num)):\n",
    "        selected_ids.append(int(sorted_counts[i]))\n",
    "        # selected_mat.append(cov_matrix.toarray()[sorted_counts[i]])\n",
    "\n",
    "#     score = sum(sum(selected_mat))/len(cov_matrix.toarray()[0])\n",
    "#     occ_score = np.count_nonzero(sum(np.array(selected_mat)))/len(cov_matrix.toarray()[0])\n",
    "    \n",
    "#     if score_bar != -1:\n",
    "#         tmp = select_num\n",
    "#         while occ_score <= score_bar:\n",
    "#             selected_ids.append(int(sorted_counts[tmp]))\n",
    "#             selected_mat.append(cov_matrix.toarray()[sorted_counts[tmp]])\n",
    "#             tmp += 1\n",
    "            \n",
    "#             score = sum(sum(selected_mat))/len(cov_matrix.toarray()[0])\n",
    "#             occ_score = np.count_nonzero(sum(np.array(selected_mat)))/len(cov_matrix.toarray()[0])\n",
    "    \n",
    "#     print(\"We select \" + str(len(selected_ids))+ \" items.\")\n",
    "#     print(\"The coverage score is \" + str(score))\n",
    "#     print(\"The occurence score is \" + str(occ_score))\n",
    "    \n",
    "    return selected_ids\n",
    "\n",
    "\n",
    "def split_into_folds(cov_matrix, fold_num):\n",
    "    folds = []\n",
    "    count_list = []\n",
    "    score_mat = cov_matrix.toarray()\n",
    "    for tmp in score_mat:\n",
    "        count_list.append(sum(tmp))\n",
    "    \n",
    "    sorted_counts = np.array(count_list).argsort()[::-1]\n",
    "    \n",
    "    folds = np.array_split(sorted_counts, fold_num)\n",
    "    \n",
    "    print(\"After spliting into \" + str(fold_num) +\" folds, we have \" +str(len(folds[0]))+ \" for each.\")\n",
    "    \n",
    "    return folds\n",
    "\n",
    "def split_into_folds_sent(cov_score_mat, fold_num):\n",
    "    folds = []\n",
    "    \n",
    "    score_list = []\n",
    "    for tmp in cov_score_mat:\n",
    "        score_list.append(max(tmp))\n",
    "        \n",
    "    folds = np.array_split(np.array(score_list).argsort()[::-1],fold_num)\n",
    "    foldwise_score = np.array_split(np.sort(np.array(score_list))[::-1],fold_num)\n",
    "    \n",
    "    print(\"folds scores: \", np.mean(foldwise_score[0]), np.mean(foldwise_score[1]), np.mean(foldwise_score[2]))\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_ids = select_data_pieces_ids(cov_matrix,10234,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"sudo_m_ids.json\",\"w\") as f:\n",
    "#     json.dump(selected_ids,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_ids = select_data_pieces_ids(cov_matrix,10234,5)\n",
    "# with open(\"sudo_l_ids.json\",\"w\") as f:\n",
    "#     json.dump(selected_ids,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sudo_set(cover_set, selected_ids, output_filename):\n",
    "    # generate the seleted/unselected set\n",
    "    with open(output_filename,\"w\") as f1:\n",
    "        with open(\"un\"+output_filename,\"w\") as f2:\n",
    "            for i,piece in enumerate(cover_set):\n",
    "                if i in selected_ids:\n",
    "                    f1.write(json.dumps(piece))\n",
    "                    f1.write(\"\\n\")\n",
    "                else:\n",
    "                    f2.write(json.dumps(piece))\n",
    "                    f2.write(\"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_sudo_set(xl, selected_ids, \"selected_l.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folds scores:  0.1300557006200449 0.08824576200596457 0.05076479611302629\n"
     ]
    }
   ],
   "source": [
    "folds = split_into_folds_sent(cov_score_mat, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,fold in enumerate(folds):\n",
    "    generate_sudo_set(xl, fold, \"split_jaccard_\"+str(i)+\".jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
